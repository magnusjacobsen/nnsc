\chapter{Conclusion}
In the introduction the following research question was asked:

\begin{displayquote}
Is it possible for an AI agent, based on the described approach and constraints, to gain a skill-level making it competitive against state-of-the-art game-specific AI agents for the game Hex?
\end{displayquote}

I have shown that it is possible, inspired by an AlphaZero approach, to teach an agent, decent game-playing skills in the game of Hex, on board sizes of 7x7 and 9x9, starting from tabula rasa. This is witnessed in the win rates against the baseline MCTS agent. 

Furthermore, I have laid out how different variants of the original approach improve playing performance, and as a result also lowers the required processing power needed to learn. These variants include: feeding game information to the algorithm slightly differently; changing the value training target; using full pre-activation residual block design instead of the original; and applying a mixed precision approach, which combines single and half-precision.

Finally, I have shown that with extended training it is possible to train an agent that is competitive against a state-of-the-art, anno 2000, game-specific AI agent for Hex.