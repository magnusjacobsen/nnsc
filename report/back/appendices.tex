\appendix
\addcontentsline{toc}{chapter}{Appendices}
\renewcommand\thefigure{\thesection.\arabic{figure}}

\chapter*{Appendices}
\renewcommand{\thesection}{\Alph{section}}

\section{Software user guide}
The code is organized in several modules:
\begin{itemize}
	\itemsep-0.3em 
	\item \textbf{root}, contains files:
	\begin{itemize}
		\itemsep-0.3em 
		\item \textit{play.py} starts the program in play mode. 
		\item \textit{train.py} starts the algorithm in training mode.
		\item \textit{controller.py} handles playing the game, when the program is in play mode, between two opponents. Conceptually it belongs in module \textit{hex}, but placed here because of how Python handles disk file lookup.
	\end{itemize}
	\item \textbf{nnsc}, with the following files:
	\begin{itemize}
		\itemsep-0.3em 
		\item \textit{nnsc.py}, contains the runnable algorithm, both the when it is in training mode and in play mode.
		\item \textit{config.py}, contains a class of the same name, that holds all the important tweakable parameters for the algorithm. 
		\item \textit{network.py}, contains the neural network.
		\item \textit{gamestorage.py}, contains a class that keeps, in accordance with a config value, the most recent self-played games in memory, for use in training the network. It is also tasked with creating data batches of images of said games.
		\item \textit{savefile.py}, contains a self-titled class, that is able to save all important objects to disk, such that the algorithm can be stopped at a certain time, and restarted later, with the same network, gamestorage, config, etc.
	\end{itemize}
	\item \textbf{hex}, with the following files:
	\begin{itemize}
		\itemsep-0.3em 
		\item \textit{gui.py}, allows for a visual and, in the case of a human player, interactive representation of a game.
		\item \textit{game.py}, contains all the game specific implementation for the game of Hex.
	\end{itemize}
	\item \textbf{ais}, contains \textit{mcts.py}, which is a simple purely UCT based agent, and \textit{random.py}, which is an agent that takes random actions. Both of these have been used for testing that the learned agents are actually increasing their ability to play the game well. 
\end{itemize}

When play.py is run it requires 5 or 6 ordered arguments. The 2 first are which agents that should play, the 3rd is the board size, the 4th is the amount of games to play, and the 5th is an optional parameter \textit{vis}, which sets the game to be played with a visual interface. Running play from a terminal could look like this:

\begin{displayquote}
{\normalfont\ttfamily python play.py nn!az mcts!2000 7 2 vis}
\end{displayquote}

Several, unordered, optional arguments, separated by spaces, can be given to train.py. Except for the paramaters \textit{save=<filename>} and \textit{load=<filename>}, if a specific argument setting is not provided, a default value will be used, in creating a config object. Running train.py from a terminal can be as simple as this:

\begin{displayquote}
{\normalfont\ttfamily python train.py save=new-test size=13}
\end{displayquote}

The parameters used for the config object, when using train.py, are:
\begin{itemize}
	\itemsep-0.3em 
	\item \textit{size=<value>}. Sets the board shape as $size\times size$. Default value is 9.
	\item \textit{sims=<value>}. Sets the number of simulations the MCTS part of the algorithm uses. Default value is 200.
	\item \textit{blocks=<value>}. Set the number of residual blocks that are used in the neural network. Default value is 19.
	\item \textit{filters=<value>}. Sets the number of channels in the convolutional layers  of the residual blocks, such that the shape of input and output will be $batch\_size \times filtes \times size \ size$. Default value is 256.
	\item \textit{actors=<value>}. Sets the amount of self-played games to be in played in batch between training the network. Default value is 50.
	\item \textit{epochs=<value>}. Sets the number of training iterations to be performed between each batch of self-playing. Default value is 10.
	\item \textit{window=<value>}. Sets the amount of most recet self-played games to be saved in gamestorage. Default value is 1000.
	\item \textit{batch=<value>}. Sets the size of the image dataset used for the individual training iterations. Default value is 512.
	\item \textit{singleprecision}. Sets the model to be using single-precision, both during training and self-playing. Default value is that mixed-precision is used. 
	\item \textit{type=<type>}. If none are set the algorithm will work similar to what is shown in figure \ref{fig-targets-az}, and use the original residual block design, as shown in figure \ref{fig-res-block}. The \textit{<type>} can be one of the following:
	\begin{itemize}
		\itemsep-0.3em
		\item \textit{u}. Sets the MCTS part of the algorithm to use the utility function for terminal states. See figure \ref{fig-targets-util}.
		\item \textit{q}. Sets the algorithm to use average mean value of root states as training value target, in accordance with figure \ref{fig-targets-q}.
		\item \textit{fpa}. Sets the model to follow both \textit{q} and use full pre-activation block design in the neural network, as seen in figure \ref{fig-fpa-block}.
	\end{itemize}
\end{itemize}

It is recommended to run the program from a console user interface that has extensive support for ANSI, since the program uses prints that manipulate the console output through escape sequences.

The following packages are also needed:
\begin{ttfamily}

pytorch (a GPU supporting CUDA is necessary)\\
torchvision\\
pillow\\
pickle\\
tk\\
matplotlib\\
numpy\\
numba\\
\end{ttfamily}
\clearpage
\section{Selected matches against Hexy}
Eight games are included here, with history provided by labels on each piece, indicating when in the sequence of play it was placed.

All games feature Hexy on expert settings, a game as first, and one as second, against: H1 with 1200 training iterations; H2 with 1,200 training iterations; H2 with 2400 training iterations; and the baseline MCTS with 10,000 simulations.

This selection has been made with the attitude that it is most interesting to see how the best performing agents are playing, and in regards to MCTS, get a perspective of what type of decisions it makes.

Hexy wins all of them except one, figure \ref{fig-h2-2400-hexy}. This against H2 with 2,400 training iterations, where Hexy is the second player (dark).

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/h1-1200-hexy.png}
	\caption{H1 1200 (light) vs Hexy (dark). Winner: Hexy}
	\label{fig-h1-1200-hexy}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/hexy-h1-1200.png}
	\caption{Hexy (light) vs H1 1200 (dark). Winner: Hexy}
	\label{fig-hexy-h1-1200}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/h2-1200-hexy.png}
	\caption{H2 1200 (light) vs Hexy (dark). Winner: Hexy}
	\label{fig-h2-1200-hexy}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/hexy-h2-1200.png}
	\caption{Hexy (light) vs H2 1200 (dark). Winner: Hexy}
	\label{fig-hexy-h2-1200}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/h2-2400-hexy.png}
	\caption{H2 2400 (light) vs Hexy (dark). Winner: H2 2400}
	\label{fig-h2-2400-hexy}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/hexy-h2-2400.png}
	\caption{Hexy (light) vs H2 2400 (dark). Winner: Hexy}
	\label{fig-hexy-h2-2400}
\end{figure}
\vspace{1cm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/mcts-hexy.png}
	\caption{baseline MCTS (light) vs Hexy (dark). Winner: Hexy}
	\label{fig-mcts-hexy}
\end{figure}
\vspace{1cm}
\begin{figure}[ht]
	\centering
	\includegraphics[width=.75\textwidth]{graphics/games/hexy-mcts.png}
	\caption{Hexy (light) vs baseline MCTS (dark). Winner: Hexy}
	\label{fig-hexy-mcts}
\end{figure}


\clearpage
\section{Bayesian Elo estimation tables}
Below is the output of running the tool \cite{Coulom} from \citeauthor{Coulom}, with the game results found in Appendix D.

\begin{table}[ht]
\small
\centering
\begin{tabular}{ c c c c c c c c c}
Rank & Name                   & Elo &   +  &  - &games &score &oppo. &draws\\
\hline
   1& Hexy (expert)          & 888&  343&  212  &  30 & 100\% &  -59 &   0\%\\
\hline
   2& H2 1200                & 659&  183&  150  &  38 &  89\% &   30 &   0\%\\
\hline
   3& H1 1200                & 644&  179&  143  &  38 &  89\% &   31 &   0\%\\
\hline
   4& H1 1000                & 478&  145&  132  &  38 &  79\% &   40 &   0\%\\
\hline
   5& baseline MCTS (10000)  & 307&   79&   76  & 142 &  75\% &  -72 &   0\%\\
\hline
   6& H2 1000                & 225&  129&  130  &  38 &  61\% &   53 &   0\%\\
\hline
   7& H1 800                 & 190&  131&  133  &  38 &  58\% &   55 &   0\%\\
\hline
   8& H2 800                 & -19&  131&  140  &  38 &  42\% &   66 &   0\%\\
\hline
   9& H1 600                 & -56&  132&  141  &  38 &  39\% &   68 &   0\%\\
\hline
  10& H2 600                 &-177&  138&  146  &  38 &  32\% &   74 &   0\%\\
\hline
  11& H2 400                 &-263&  143&  150  &  38 &  26\% &   79 &   0\%\\
\hline
  12& H1 400                 &-400&  150&  164  &  38 &  18\% &   86 &   0\%\\
\hline
  13& H1 200                 &-504&  158&  178  &  38 &  13\% &   91 &   0\%\\
\hline
  14& H2 200                 &-505&  161&  182  &  38 &  13\% &   91 &   0\%\\
\hline
  15& H1 0                   &-620&  167&  203  &  38 &   8\% &   97 &   0\%\\
\hline
  16& H2 0                   &-848&  199&  339  &  38 &   0\% &  109 &   0\%\\
\hline
\end{tabular}
\end{table}

Adding the two games between Hexy and H2, with 2,400 training iterations, gives the following table:

\begin{table}[ht]
\small
\centering
\begin{tabular}{ c c c c c c c c c}

Rank &Name&                    Elo  &  +  &  - &games &score &oppo. &draws \\
\hline
   1& Hexy (expert)         &  843&  229&  181  &  32 &  97\%  & -53 &   0\%\\
\hline
   2& H2 2400               &  843&  335&  342  &   2 &  50\%  & 843 &   0\%\\
\hline
   3& H2 1200               &  607&  184&  151  &  38 &  89\%  & -23 &   0\%\\
\hline
   4& H1 1200               &  593&  180&  144  &  38 &  89\%  & -22  &  0\%\\
\hline
   5& H1 1000               &  426&  146&  132  &  38 &  79\%  & -13  &  0\%\\
\hline
   6& baseline MCTS (10000) &  254&   79&   76  & 142 &  75\%  &-125  &  0\%\\
\hline
   7& H2 1000               &  172&  130&  131  &  38 &  61\%  &   0  &  0\%\\
\hline
   8& H1 800                &  137&  132&  134  &  38 &  58\%  &   2  &  0\%\\
\hline
   9& H2 800                &  -73&  132&  141  &  38 &  42\%  &  13  &  0\%\\
\hline
  10& H1 600                & -109&  132&  142  &  38 &  39\%  &  15  &  0\%\\
\hline
  11& H2 600                & -230&  139&  147  &  38 &  32\%  &  21  &  0\%\\
\hline
  12& H2 400                & -317&  143&  151  &  38 &  26\%  &  26  &  0\%\\
\hline
  13& H1 400                & -453&  151&  165  &  38 &  18\%  &  33  &  0\%\\
\hline
  14& H1 200                & -558&  158&  179  &  38 &  13\%  &  39  &  0\%\\
\hline
  15& H2 200                & -559&  161&  183  &  38 &  13\%  &  39  &  0\%\\
\hline
  16& H1 0                  & -675&  168&  204  &  38 &   8\%  &  45  &  0\%\\
\hline
  17& H2 0                  & -903&  200&  333  &  38 &   0\%  &  57  &  0\%\\
  \hline
\end{tabular}
\end{table}

\input{back/appendix-games}
\clearpage
\section{Training loss rate for H2 after 2400 training iterations}
Below is a graph of the training losses for H2, after it has played 12,000 games of self-play, and done 2,400 training iterations.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.9\textwidth]{figures/loss-2400}
	\caption{Training loss rates for H2 after 2,400 training iterations.}
	\label{fig-loss-2400}
\end{figure}
